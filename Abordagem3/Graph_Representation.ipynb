{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a453efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representação do grafo - Matriz de adjacência\n",
    "# Por exemplo\n",
    "\n",
    "# 0 é o vértice da imagem toda\n",
    "# 1 ao 4 tenho os vértices referentes aos patches\n",
    "# 5 é o vértice da pergunta toda\n",
    "# a partir de 5 é o vértice de cada palavra\n",
    "\n",
    "\"\"\"\n",
    "#     visao      #        nlp        #\n",
    "[0, 1, 2, ..., 49, 50, 51, ..., 60]\n",
    "[1, ...                               ]\n",
    "[2, ...                               ]\n",
    "[..., ...                             ]\n",
    "[49, ...                             ]\n",
    "[50, ...                             ]\n",
    "[..., ...                             ]\n",
    "[60, ...                             ]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Atenção ao seguinte:\n",
    "# - Self loop, ou seja, aresta do vértice pra ele mesmo (diagonal = 1)\n",
    "# - Todas as palavras vão estar conectadas com todos os pedaços da imagem e imagem inteira\n",
    "# - Conexões entre as palavras estão no arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name_arq):\n",
    "\n",
    "    data = {}\n",
    "    with open(name_arq, 'rb') as fr:\n",
    "        try:\n",
    "            while True:\n",
    "                data.update(pickle.load(fr))\n",
    "        except EOFError:\n",
    "            pass\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_connections_patches():\n",
    "\n",
    "    source = []\n",
    "    target = []\n",
    "\n",
    "    matrix_patch = np.array(list(range(1,5))).reshape((2,2))\n",
    "\n",
    "    for p in range(1,5):\n",
    "\n",
    "        pos = np.argwhere(matrix_patch == p).tolist()[0]\n",
    "        row = pos[0]\n",
    "        col = pos[1]\n",
    "\n",
    "        if (row-1) >= 0:\n",
    "            neighbour_up = matrix_patch[row-1, col]\n",
    "        else:\n",
    "            neighbour_up = -100\n",
    "        if (row+1) < 2:\n",
    "            neighbour_down = matrix_patch[row+1, col]\n",
    "        else:\n",
    "            neighbour_down = -100\n",
    "        if (col-1) >= 0:\n",
    "            neighbour_left = matrix_patch[row, col-1]\n",
    "        else:\n",
    "            neighbour_left = -100\n",
    "        if (col+1) < 2:\n",
    "            neighbour_right = matrix_patch[row, col+1]\n",
    "        else:\n",
    "            neighbour_right = -100\n",
    "\n",
    "        neighbours = sorted([n for n in [neighbour_up, neighbour_down, neighbour_left, neighbour_right] if n != -100])\n",
    "\n",
    "        source = source + [p]*len(neighbours)\n",
    "        target = target + neighbours\n",
    "\n",
    "    return source, target\n",
    "\n",
    "def get_edges_common():\n",
    "\n",
    "    # Realiza a ligação entre os patches da imagem\n",
    "    source, target = get_connections_patches()\n",
    "\n",
    "    # Realiza a ligação do vértice da imagem com todos os patches e vice-versa\n",
    "    v_patches = list(range(1,5))\n",
    "    v_img = [0]*4\n",
    "\n",
    "    source = source + v_img\n",
    "    target = target + v_patches\n",
    "    source = source + v_patches\n",
    "    target = target + v_img\n",
    "\n",
    "    # Realiza a ligação do vértice da pergunta com os vértices da imagem e patches e vice-versa\n",
    "    v_perg = [5]*5\n",
    "    v_img_patches = list(range(0,5))\n",
    "\n",
    "    source = source + v_perg\n",
    "    target = target + v_img_patches\n",
    "    source = source + v_img_patches\n",
    "    target = target + v_perg\n",
    "\n",
    "    # add self-loop desde o vértice da imagem até o vértice da pergunta\n",
    "    source = source + list(range(0,6))\n",
    "    target = target + list(range(0,6))\n",
    "\n",
    "    return source, target\n",
    "\n",
    "def define_edges(info_nlp, img, source_common, target_common):\n",
    "\n",
    "    # Inicia a formação das arestas especificas de cada imagem\n",
    "\n",
    "    source = source_common.copy()\n",
    "    target = target_common.copy()\n",
    "\n",
    "    # Realiza a conexão das palavras com a imagem, todos os patches da imagem, pergunta\n",
    "\n",
    "    tam_perg = info_nlp[img][\"len_perg\"]\n",
    "    node_img = list(range(6, 6+tam_perg))\n",
    "\n",
    "    for n in node_img:\n",
    "\n",
    "        source = source + [n]*6\n",
    "        target = target + list(range(0,6))\n",
    "        source = source + list(range(0,6))\n",
    "        target = target + [n]*6\n",
    "\n",
    "        # add self-loop in each word\n",
    "        source = source + [n]\n",
    "        target = target + [n]\n",
    "\n",
    "    # Realiza a conexão das palavras com seus pares sintático/bidirecional\n",
    "\n",
    "    for k in range(0, tam_perg):\n",
    "\n",
    "        connections_words = info_nlp[img][\"word_\"+str(k)][\"ligacoes\"]\n",
    "        connections_words = [i+6 for i in connections_words]\n",
    "\n",
    "        for n2 in node_img:\n",
    "            source = source + [n2]*len(connections_words)\n",
    "            target = target + connections_words\n",
    "\n",
    "    return source, target\n",
    "\n",
    "def Get_graphs(type_base):\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    info_visao = loadData(type_base+\"_info_visao.pkl\")\n",
    "    info_nlp = loadData(type_base+\"_info_nlp\")\n",
    "    info_answers = loadData(type_base+\"_info_answers\")\n",
    "\n",
    "    images = list(info_visao.keys())\n",
    "\n",
    "    source_common, target_common = get_edges_common()\n",
    "\n",
    "    for img in images:\n",
    "\n",
    "        # features de visão + features de nlp\n",
    "        features = np.concatenate((info_visao[img].detach().numpy(), info_nlp[img][\"embeddings\"]))\n",
    "\n",
    "        # Calculate the L2 norm of the data\n",
    "        #norm = np.linalg.norm(features)\n",
    "        #normalized_data = features / norm\n",
    "\n",
    "        #x = torch.tensor(normalized_data)\n",
    "        x = torch.tensor(features)\n",
    "\n",
    "        # Define as respostas referentes a cada grafo\n",
    "        y = info_answers[img]\n",
    "        y = pd.DataFrame(y).answer.values.tolist()\n",
    "\n",
    "        # Cria as arestas\n",
    "        source, target = define_edges(info_nlp, img, source_common, target_common)\n",
    "        edge_index = torch.tensor([source, target], dtype=torch.long)\n",
    "\n",
    "        # Cria os grafos\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deee845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graphs(dataset, name_arq):\n",
    "    torch.save(dataset, name_arq+\"_graphs.pt\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name_arq = \"val\"\n",
    "dataset = Get_graphs(name_arq)\n",
    "save_graphs(dataset, name_arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3342c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[idx].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[idx].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[idx].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dda6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[idx].num_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
