{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a453efd",
   "metadata": {
    "id": "5a453efd"
   },
   "outputs": [],
   "source": [
    "# Bibliotecas necessárias\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.nn import Linear\n",
    "from itertools import chain\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8PpBrPNBoe",
   "metadata": {
    "id": "ab8PpBrPNBoe"
   },
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "\n",
    "# Seed the behavior of the environment variable\n",
    "os.environ['PYTHONHASHSEED'] = str(1)\n",
    "# Seed numpy's instance in case you are using numpy's random number generator, shuffling operations, ...\n",
    "np.random.seed(1)\n",
    "\n",
    "# In general seed PyTorch operations\n",
    "torch.manual_seed(0)\n",
    "# If you are using CUDA on 1 GPU, seed it\n",
    "torch.cuda.manual_seed(0)\n",
    "# If you are using CUDA on more than 1 GPU, seed them all\n",
    "torch.cuda.manual_seed_all(0)\n",
    "# Disable the inbuilt cudnn auto-tuner that finds the best algorithm to use for your hardware.\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Certain operations in Cudnn are not deterministic, and this line will force them to behave!\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc2e8a",
   "metadata": {
    "id": "a9cc2e8a"
   },
   "outputs": [],
   "source": [
    "# Faz a leitura dos grafos das bases de treino, validação e teste\n",
    "\n",
    "train_data = torch.load(\"train_graphs.pt\")\n",
    "val_data = torch.load(\"val_graphs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Considera que a classe é a resposta mais frequente\n",
    "def redefine_target(base):\n",
    "\n",
    "    df_filtro = pd.DataFrame(base)\n",
    "    df_filtro[2] = df_filtro[2].apply(lambda x: x[1])\n",
    "    df_filtro[\"y\"] = df_filtro[2].apply(lambda x: pd.DataFrame(x).value_counts().index[0][0])\n",
    "\n",
    "    for i in range(len(base)):\n",
    "        base[i].y = df_filtro[\"y\"][i]\n",
    "\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lGV8TwgGQ8IO",
   "metadata": {
    "id": "lGV8TwgGQ8IO"
   },
   "outputs": [],
   "source": [
    "# Função que pega as 3000 respostas mais frequentes da base de treino\n",
    "# Representando 96% da base de treino e 90% da validação\n",
    "\n",
    "def get_most_common_answers(train_data, neurons_final_layer):\n",
    "\n",
    "    df_filtro = pd.DataFrame(train_data)\n",
    "    df_filtro[\"img\"] = list(range(df_filtro.shape[0]))\n",
    "    df_filtro[2] = df_filtro[2].apply(lambda x: x[1])\n",
    "    df_filtro = df_filtro.explode(2)\n",
    "    df_filtro.rename(columns = {2: \"answer\"}, inplace = True)\n",
    "    all_answers_train = df_filtro[[\"answer\"]].value_counts().reset_index()\n",
    "    top_k = all_answers_train.head(neurons_final_layer).answer.tolist()\n",
    "\n",
    "    return all_answers_train, top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f37fe",
   "metadata": {
    "id": "084f37fe"
   },
   "outputs": [],
   "source": [
    "# Obtém as classes com base nos dados de treinamento\n",
    "neurons_final_layer = 3000\n",
    "all_answers_train, classes_train = get_most_common_answers(train_data, neurons_final_layer)\n",
    "\n",
    "# Define o codificador e decodificador das classes a ser usado na etapa de treinamento/validação\n",
    "encoder_label = {w: i for i,w in enumerate(classes_train)}\n",
    "decoder_label = {w: i for w,i in enumerate(classes_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6ca1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34c6ca1b",
    "outputId": "df7b0793-b142-4dfc-ecaa-4efc7cc2b5c4"
   },
   "outputs": [],
   "source": [
    "print(\"Quantidade de classes usadas: \", neurons_final_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hr-TkkyoV3mc",
   "metadata": {
    "id": "Hr-TkkyoV3mc"
   },
   "outputs": [],
   "source": [
    "# Filtra as bases para que sejam analisados somente grafos cuja resposta é conhecida,\n",
    "# ou seja, está no top 3000 definido\n",
    "\n",
    "def filter_base_based_classes_train(base_grafo, classes_train):\n",
    "\n",
    "  indices = []\n",
    "  for i in range(len(base_grafo)):\n",
    "\n",
    "      if len(list(set(base_grafo[i].y)&set(classes_train))) != 0:\n",
    "          indices.append(i)\n",
    "  graphs = [base_grafo[i] for i in indices]\n",
    "\n",
    "  return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uWfgOuhgWQAA",
   "metadata": {
    "id": "uWfgOuhgWQAA"
   },
   "outputs": [],
   "source": [
    "train_data = filter_base_based_classes_train(train_data, classes_train)\n",
    "val_data = filter_base_based_classes_train(val_data, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j-_KoVQ-0esh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-_KoVQ-0esh",
    "outputId": "0f7caa10-7b2b-4356-f660-14a07462c485"
   },
   "outputs": [],
   "source": [
    "print(\"Tamanho da base de treino: \", len(train_data))\n",
    "print(\"Tamanho da base de validação: \", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dyRkjixw0WTt",
   "metadata": {
    "id": "dyRkjixw0WTt"
   },
   "outputs": [],
   "source": [
    "# Load the data sets into dataloader\n",
    "# We will train the graph classification task on a batch of 32 graphs\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last = True)\n",
    "valid_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WGTlIveTdJ9n",
   "metadata": {
    "id": "WGTlIveTdJ9n"
   },
   "outputs": [],
   "source": [
    "def define_class_weights(all_answers_train, neurons_final_layer):\n",
    "\n",
    "  all_answers_train = all_answers_train.head(neurons_final_layer)\n",
    "  all_answers_train[\"weight\"] = all_answers_train[0]/all_answers_train[0].sum()\n",
    "  class_weights = all_answers_train[\"weight\"].values.tolist()\n",
    "\n",
    "  return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tnz_2I4CdJtM",
   "metadata": {
    "id": "Tnz_2I4CdJtM"
   },
   "outputs": [],
   "source": [
    "classes_weights = define_class_weights(all_answers_train, neurons_final_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dJrbW1ZjthYj",
   "metadata": {
    "id": "dJrbW1ZjthYj"
   },
   "outputs": [],
   "source": [
    "# Define a arquitetura do modelo: Graph Attention Network\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.gat1 = GATv2Conv(dim_in, 300, heads=8, add_self_loops = False)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.gat2 = GATv2Conv(300*8, 300, heads=4, add_self_loops = False)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        self.layer_3 = torch.nn.Linear(300*4, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.gat1(x, edge_index)\n",
    "        #features, att_weight = self.gat1(x, edge_index, return_attention_weights = True)\n",
    "        x = self.dropout3(x)\n",
    "        #x = self.dropout3(features)\n",
    "        features, att_weight = self.gat2(x, edge_index, return_attention_weights = True)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(features, batch)  # [batch_size, hidden_channels]\n",
    "        x = self.dropout4(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x, att_weight, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9847b5",
   "metadata": {
    "id": "0d9847b5"
   },
   "outputs": [],
   "source": [
    "# Calcula a acurácia do modelo\n",
    "def accuracy(pred, y_10):\n",
    "\n",
    "    tot_acc = []\n",
    "    for i in range(len(pred)):\n",
    "        cur_acc = np.minimum(1.0, y_10[i].count(pred[i])/3.0)\n",
    "        tot_acc.append(cur_acc)\n",
    "\n",
    "    return np.mean(tot_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff000028",
   "metadata": {
    "id": "ff000028"
   },
   "outputs": [],
   "source": [
    "# Realiza a inserção de logs com as informações sobre o treinamento do modelo\n",
    "def insert_log(e, loss_train_mean, acc_train_mean, loss_val_mean, acc_val_mean):\n",
    "\n",
    "  logs = open('logs.txt', 'a')\n",
    "  log_epoch = f'Epoch {e} \\t Training Loss: {loss_train_mean} \\t Training Acc: {acc_train_mean} \\t Validation Loss: {loss_val_mean} \\t Validation Acc: {acc_val_mean}'+\"\\n\"\n",
    "  logs.write(log_epoch)\n",
    "  logs.close()\n",
    "\n",
    "def insert_time_execution(start, end):\n",
    "\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  logs = open('logs.txt', 'a')\n",
    "  log_time = 'Time execution:'+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)+\"\\n\"\n",
    "  logs.write(log_time)\n",
    "  logs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3d934",
   "metadata": {
    "id": "32d3d934"
   },
   "outputs": [],
   "source": [
    "# Salva o modelo sempre que apresentar o melhor resultado\n",
    "def checkpoint(model, e, path):\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c021f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a representação da saída do modelo\n",
    "def get_output_representation(encoder_label, y_10, classes_train, neurons_final_layer):\n",
    "\n",
    "  df = pd.DataFrame({\"answer\":y_10}).value_counts().reset_index()\n",
    "  df.rename(columns={0: \"freq\"}, inplace= True)\n",
    "  df[\"answer_encode\"] = df[\"answer\"].apply(lambda x: encoder_label[x] if x in classes_train else pd.NA)\n",
    "  df = df.dropna()\n",
    "  df[\"percentage\"] = df[\"freq\"]/10\n",
    "\n",
    "  targets_elem = np.zeros(neurons_final_layer)\n",
    "  targets_elem[df.answer_encode.tolist()] = df.percentage.values\n",
    "\n",
    "  return list(targets_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_VNdnEyMhMz_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VNdnEyMhMz_",
    "outputId": "1ce05b78-ec0e-4e55-e971-7040ef3d1723"
   },
   "outputs": [],
   "source": [
    "# Define dispositivo utilizado para treinamento (GPU/ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo sendo usado: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t5Vx154tK2aq",
   "metadata": {
    "id": "t5Vx154tK2aq"
   },
   "outputs": [],
   "source": [
    "# Define o pipeline de treinamento\n",
    "def pipeline_train(model, loader, device, optimizer, e, decoder_label, encoder_label, classes_train,\n",
    "                   targets_base, base, neurons_final_layer, classes_weights, criterion):\n",
    "\n",
    "  predictions = []\n",
    "  targets_multi = []\n",
    "  base_loss = 0.0\n",
    "  idx = 0\n",
    "\n",
    "  for data in loader:\n",
    "\n",
    "        # Transfer Data to GPU if available\n",
    "        data = data.to(device)\n",
    "\n",
    "        if base == \"train\":\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            x,_, _ = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        else:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Forward Pass\n",
    "                x, _, _ = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        # predict answer\n",
    "        pred = x.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        predictions = predictions + [decoder_label[i] for i in pred]\n",
    "        targets_multi = targets_multi + data.y\n",
    "\n",
    "        # Find the Loss\n",
    "        if e == 0:\n",
    "          # Calcula os targets\n",
    "          resps = [get_output_representation(encoder_label, i, classes_train, neurons_final_layer) for i in data.y]\n",
    "          targets_base.append(torch.tensor(resps, dtype=torch.float))\n",
    "\n",
    "        loss = criterion(x, targets_base[idx].to(device))\n",
    "\n",
    "        if base == \"train\":\n",
    "          # Calculate gradients\n",
    "          loss.backward()\n",
    "          # Update Weights\n",
    "          optimizer.step()\n",
    "\n",
    "        # Calculate Loss\n",
    "        base_loss += loss.item()\n",
    "        idx += 1\n",
    "\n",
    "  # Compute accuracy metric\n",
    "  acc = accuracy(predictions, targets_multi)\n",
    "\n",
    "  return acc, base_loss, targets_base, model, optimizer, classes_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ew4guS891l0G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ew4guS891l0G",
    "outputId": "79b6bde7-d7d3-4cae-e314-1f19ab4e9e7e"
   },
   "outputs": [],
   "source": [
    "# Define o modelo a ser usado\n",
    "model = GAT(train_data[0].num_features, neurons_final_layer)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FIhP9QQwLAyf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIhP9QQwLAyf",
    "outputId": "0638e8ff-c3c9-490c-ac1b-70f1262385c8"
   },
   "outputs": [],
   "source": [
    "# Realiza o treinamento do modelo\n",
    "\n",
    "# Declaring Optimizer\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor(classes_weights).to(device))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.9)\n",
    "\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(weight=classes_weights, reduction='none')\n",
    "\n",
    "best_accuracy = -1\n",
    "best_epoch = -1\n",
    "\n",
    "# Training with Validation\n",
    "epochs = 10\n",
    "\n",
    "early_stop_thresh = epochs\n",
    "\n",
    "targets_train = []\n",
    "targets_val = []\n",
    "\n",
    "classes_weights_train = []\n",
    "classes_weights_val = []\n",
    "\n",
    "start = time.time()\n",
    "for e in tqdm(range(epochs)):\n",
    "\n",
    "    model.train()\n",
    "    acc_train, train_loss, targets_train, model, optimizer, classes_weights_train = pipeline_train(model, train_loader, device, optimizer, e, decoder_label,\n",
    "                                                              encoder_label, classes_train,targets_train,\n",
    "                                                              \"train\", neurons_final_layer, classes_weights, criterion)\n",
    "\n",
    "    loss_train_mean = round((train_loss / len(train_loader)), 2)\n",
    "\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    acc_val, val_loss, targets_val, model, optimizer, classes_weights_val = pipeline_train(model, valid_loader, device, optimizer, e, decoder_label,\n",
    "                                                          encoder_label, classes_train, targets_val,\n",
    "                                                          \"val\", neurons_final_layer, classes_weights, criterion)\n",
    "\n",
    "    loss_val_mean = round((val_loss / len(valid_loader)), 2)\n",
    "\n",
    "    if  acc_val >= best_accuracy:\n",
    "        best_accuracy = acc_val\n",
    "        best_epoch = e\n",
    "        checkpoint(model, e, \"best_model.pth\")\n",
    "    elif e - best_epoch > early_stop_thresh:\n",
    "        print(\"Early stopped training at epoch %d\" % e)\n",
    "        break  # terminate the training loop\n",
    "\n",
    "    print(f'Epoch {e} \\t Training Loss: {loss_train_mean} \\t Training Acc: {acc_train} \\t Validation Loss: {loss_val_mean} \\t Validation Acc: {acc_val}')\n",
    "    insert_log(e, loss_train_mean, acc_train, loss_val_mean, acc_val)\n",
    "\n",
    "end = time.time()\n",
    "insert_time_execution(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.load(\"test_graphs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbBL3kkVt9_k",
   "metadata": {
    "id": "fbBL3kkVt9_k"
   },
   "outputs": [],
   "source": [
    "# Define a avaliação sobre a base de teste\n",
    "def inference_model(model, test_data, decoder_label, device):\n",
    "\n",
    "  checkpoint = torch.load(\"best_model.pth\")\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "  results = []\n",
    "\n",
    "  for data in tqdm(test_loader):\n",
    "\n",
    "    data = data.to(device)\n",
    "    name_img = data.y[0]\n",
    "    model.eval()\n",
    "    # Forward Pass\n",
    "    x, _, _ = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "    # predict answer\n",
    "    pred = x.argmax(dim=1).cpu().numpy()\n",
    "    pred = [decoder_label[i] for i in pred][0]\n",
    "\n",
    "    results.append((name_img, pred))\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19QEeoCuBy9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b19QEeoCuBy9",
    "outputId": "dd216d3e-6de6-4d33-b42a-2fe7a2424e87"
   },
   "outputs": [],
   "source": [
    "# Realiza inferência sobre a base de teste\n",
    "results = inference_model(model, test_data, decoder_label, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cVUZZ1OouEU1",
   "metadata": {
    "id": "cVUZZ1OouEU1"
   },
   "outputs": [],
   "source": [
    "# Função para formatar e salvar os resultados da base de teste\n",
    "def format_save_results(results):\n",
    "\n",
    "  final_results = []\n",
    "\n",
    "  for i in range(len(results)):\n",
    "    name_img = results[i][0]\n",
    "    answer = results[i][1]\n",
    "    final_results.append({\"image\": name_img, \"answer\": answer})\n",
    "\n",
    "  with open(\"results_test.json\", \"w\") as outfile:\n",
    "    json.dump(final_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tE82xPJZuKEc",
   "metadata": {
    "id": "tE82xPJZuKEc"
   },
   "outputs": [],
   "source": [
    "# Salva resultados\n",
    "format_save_results(results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
